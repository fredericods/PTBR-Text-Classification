{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\frederico.souza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\frederico.souza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "C:\\ProgramData\\Anaconda3\\envs\\audio-analysis\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3072: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "from emoji import UNICODE_EMOJI\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Definindo recursos nltk em português\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "portuguese_stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "rslps_stemmer = nltk.stem.RSLPStemmer()\n",
    "snowball_stemmer = nltk.stem.snowball.SnowballStemmer('portuguese', ignore_stopwords=False)\n",
    "\n",
    "# Carregando modelo pt-br spacy\n",
    "nlp = spacy.load(\"pt_core_news_lg\")\n",
    "\n",
    "# Import data\n",
    "data = pd.read_csv('B2W-Reviews01.csv',sep=';')\n",
    "\n",
    "# Random seed\n",
    "seed = 0\n",
    "\n",
    "# Define train, validation, test split ratios\n",
    "train_ratio = 0.80\n",
    "validation_ratio = 0.10\n",
    "test_ratio = 0.10\n",
    "\n",
    "# Define train, validation, test labels for 2-class problem\n",
    "data['split_2'] = 'train'\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, data.recommend_to_a_friend.values, test_size=1-train_ratio, random_state=seed)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio+validation_ratio), random_state=seed)\n",
    "data.loc[x_val.index.values, 'split_2'] = 'valid'\n",
    "data.loc[x_test.index.values, 'split_2'] = 'test'\n",
    "\n",
    "# Define train, validation, test labels for 5-class problem\n",
    "data['split_5'] = 'train'\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, data.overall_rating.values, test_size=1-train_ratio, random_state=seed)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio+validation_ratio), random_state=seed)\n",
    "data.loc[x_val.index.values, 'split_5'] = 'valid'\n",
    "data.loc[x_test.index.values, 'split_5'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_brand</th>\n",
       "      <th>site_category_lv1</th>\n",
       "      <th>site_category_lv2</th>\n",
       "      <th>review_title</th>\n",
       "      <th>overall_rating</th>\n",
       "      <th>recommend_to_a_friend</th>\n",
       "      <th>review_text</th>\n",
       "      <th>reviewer_birth_year</th>\n",
       "      <th>reviewer_gender</th>\n",
       "      <th>reviewer_state</th>\n",
       "      <th>split_2</th>\n",
       "      <th>split_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:11:28</td>\n",
       "      <td>d0fb1ca69422530334178f5c8624aa7a99da47907c44de...</td>\n",
       "      <td>132532965</td>\n",
       "      <td>Notebook Asus Vivobook Max X541NA-GO472T Intel...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Informática</td>\n",
       "      <td>Notebook</td>\n",
       "      <td>Bom</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Estou contente com a compra entrega rápida o ú...</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>F</td>\n",
       "      <td>RJ</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 00:13:48</td>\n",
       "      <td>014d6dc5a10aed1ff1e6f349fb2b059a2d3de511c7538a...</td>\n",
       "      <td>22562178</td>\n",
       "      <td>Copo Acrílico Com Canudo 500ml Rocie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Utilidades Domésticas</td>\n",
       "      <td>Copos, Taças e Canecas</td>\n",
       "      <td>Preço imbatível, ótima qualidade</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Por apenas R$1994.20,eu consegui comprar esse ...</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>M</td>\n",
       "      <td>SC</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 00:26:02</td>\n",
       "      <td>44f2c8edd93471926fff601274b8b2b5c4824e386ae4f2...</td>\n",
       "      <td>113022329</td>\n",
       "      <td>Panela de Pressão Elétrica Philips Walita Dail...</td>\n",
       "      <td>philips walita</td>\n",
       "      <td>Eletroportáteis</td>\n",
       "      <td>Panela Elétrica</td>\n",
       "      <td>ATENDE TODAS AS EXPECTATIVA.</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>SUPERA EM AGILIDADE E PRATICIDADE OUTRAS PANEL...</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>M</td>\n",
       "      <td>SP</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 00:35:54</td>\n",
       "      <td>ce741665c1764ab2d77539e18d0e4f66dde6213c9f0863...</td>\n",
       "      <td>113851581</td>\n",
       "      <td>Betoneira Columbus - Roma Brinquedos</td>\n",
       "      <td>roma jensen</td>\n",
       "      <td>Brinquedos</td>\n",
       "      <td>Veículos de Brinquedo</td>\n",
       "      <td>presente mais que desejado</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>MEU FILHO AMOU! PARECE DE VERDADE COM TANTOS D...</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>F</td>\n",
       "      <td>SP</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 01:00:28</td>\n",
       "      <td>7d7b6b18dda804a897359276cef0ca252f9932bf4b5c8e...</td>\n",
       "      <td>131788803</td>\n",
       "      <td>Smart TV LED 43\" LG 43UJ6525 Ultra HD 4K com C...</td>\n",
       "      <td>lg</td>\n",
       "      <td>TV e Home Theater</td>\n",
       "      <td>TV</td>\n",
       "      <td>Sem duvidas, excelente</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A entrega foi no prazo, as americanas estão de...</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>M</td>\n",
       "      <td>MG</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132368</th>\n",
       "      <td>2018-05-31 23:30:50</td>\n",
       "      <td>15f20e95ff44163f3175aaf67a5ae4a94d5030b409e521...</td>\n",
       "      <td>17962233</td>\n",
       "      <td>Carregador De Pilha Sony + 4 Pilhas Aa 2500mah</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Câmeras e Filmadoras</td>\n",
       "      <td>Acessórios para Câmeras e Filmadoras</td>\n",
       "      <td>Ótimo produto!</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Vale muito, estou usando no controle do Xbox e...</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>M</td>\n",
       "      <td>RS</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132369</th>\n",
       "      <td>2018-05-31 23:42:25</td>\n",
       "      <td>def7cf9028b0673ab8bca3b1d06e085461fafb88cd48d9...</td>\n",
       "      <td>132631701</td>\n",
       "      <td>Mop Giratório Fit + Refil Extra - At Home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Utilidades Domésticas</td>\n",
       "      <td>Material de Limpeza</td>\n",
       "      <td>Sensacional</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Prático e barato, super indico o produto para ...</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>F</td>\n",
       "      <td>SP</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132370</th>\n",
       "      <td>2018-05-31 23:44:16</td>\n",
       "      <td>7bcbf542f5d7dd9a9a192a6805adba7a7a4c1ce3bf00df...</td>\n",
       "      <td>16095859</td>\n",
       "      <td>Fita Led 5m Rgb 3528 Siliconada Com 300 Leds C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Automotivo</td>\n",
       "      <td>Iluminação</td>\n",
       "      <td>Ótimo produto</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Chegou antes do prazo previsto e corresponde a...</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>F</td>\n",
       "      <td>PR</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132371</th>\n",
       "      <td>2018-05-31 23:46:48</td>\n",
       "      <td>e6fb0b19277d01c2a300c7837a105f3c369377e92f9c19...</td>\n",
       "      <td>6774907</td>\n",
       "      <td>Etiquetas Jurídicas Vade Mecum - Marca Fácil</td>\n",
       "      <td>marca facil</td>\n",
       "      <td>Papelaria</td>\n",
       "      <td>Material de Escritório</td>\n",
       "      <td>O produto não é bom.</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>Material fraco, poderia ser melhor. Ficou deve...</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>M</td>\n",
       "      <td>RJ</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132372</th>\n",
       "      <td>2018-05-31 23:50:33</td>\n",
       "      <td>ea9467aa73271fb4f68c04f4dd4f4eef304d6ee85441fb...</td>\n",
       "      <td>114081902</td>\n",
       "      <td>Painel de Fotos Bee Colection Rue Bac (74x94x3...</td>\n",
       "      <td>kapos</td>\n",
       "      <td>Decoração</td>\n",
       "      <td>Painel de Fotos</td>\n",
       "      <td>Produto não entregue</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>Comprei esse produto, quando chegou estava com...</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>F</td>\n",
       "      <td>ES</td>\n",
       "      <td>train</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132373 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            submission_date  \\\n",
       "0       2018-01-01 00:11:28   \n",
       "1       2018-01-01 00:13:48   \n",
       "2       2018-01-01 00:26:02   \n",
       "3       2018-01-01 00:35:54   \n",
       "4       2018-01-01 01:00:28   \n",
       "...                     ...   \n",
       "132368  2018-05-31 23:30:50   \n",
       "132369  2018-05-31 23:42:25   \n",
       "132370  2018-05-31 23:44:16   \n",
       "132371  2018-05-31 23:46:48   \n",
       "132372  2018-05-31 23:50:33   \n",
       "\n",
       "                                              reviewer_id product_id  \\\n",
       "0       d0fb1ca69422530334178f5c8624aa7a99da47907c44de...  132532965   \n",
       "1       014d6dc5a10aed1ff1e6f349fb2b059a2d3de511c7538a...   22562178   \n",
       "2       44f2c8edd93471926fff601274b8b2b5c4824e386ae4f2...  113022329   \n",
       "3       ce741665c1764ab2d77539e18d0e4f66dde6213c9f0863...  113851581   \n",
       "4       7d7b6b18dda804a897359276cef0ca252f9932bf4b5c8e...  131788803   \n",
       "...                                                   ...        ...   \n",
       "132368  15f20e95ff44163f3175aaf67a5ae4a94d5030b409e521...   17962233   \n",
       "132369  def7cf9028b0673ab8bca3b1d06e085461fafb88cd48d9...  132631701   \n",
       "132370  7bcbf542f5d7dd9a9a192a6805adba7a7a4c1ce3bf00df...   16095859   \n",
       "132371  e6fb0b19277d01c2a300c7837a105f3c369377e92f9c19...    6774907   \n",
       "132372  ea9467aa73271fb4f68c04f4dd4f4eef304d6ee85441fb...  114081902   \n",
       "\n",
       "                                             product_name   product_brand  \\\n",
       "0       Notebook Asus Vivobook Max X541NA-GO472T Intel...             NaN   \n",
       "1                    Copo Acrílico Com Canudo 500ml Rocie             NaN   \n",
       "2       Panela de Pressão Elétrica Philips Walita Dail...  philips walita   \n",
       "3                    Betoneira Columbus - Roma Brinquedos     roma jensen   \n",
       "4       Smart TV LED 43\" LG 43UJ6525 Ultra HD 4K com C...              lg   \n",
       "...                                                   ...             ...   \n",
       "132368     Carregador De Pilha Sony + 4 Pilhas Aa 2500mah             NaN   \n",
       "132369          Mop Giratório Fit + Refil Extra - At Home             NaN   \n",
       "132370  Fita Led 5m Rgb 3528 Siliconada Com 300 Leds C...             NaN   \n",
       "132371       Etiquetas Jurídicas Vade Mecum - Marca Fácil     marca facil   \n",
       "132372  Painel de Fotos Bee Colection Rue Bac (74x94x3...           kapos   \n",
       "\n",
       "            site_category_lv1                     site_category_lv2  \\\n",
       "0                 Informática                              Notebook   \n",
       "1       Utilidades Domésticas                Copos, Taças e Canecas   \n",
       "2             Eletroportáteis                       Panela Elétrica   \n",
       "3                  Brinquedos                 Veículos de Brinquedo   \n",
       "4           TV e Home Theater                                    TV   \n",
       "...                       ...                                   ...   \n",
       "132368   Câmeras e Filmadoras  Acessórios para Câmeras e Filmadoras   \n",
       "132369  Utilidades Domésticas                   Material de Limpeza   \n",
       "132370             Automotivo                            Iluminação   \n",
       "132371              Papelaria                Material de Escritório   \n",
       "132372              Decoração                       Painel de Fotos   \n",
       "\n",
       "                            review_title  overall_rating  \\\n",
       "0                                    Bom               4   \n",
       "1       Preço imbatível, ótima qualidade               4   \n",
       "2           ATENDE TODAS AS EXPECTATIVA.               4   \n",
       "3             presente mais que desejado               4   \n",
       "4                 Sem duvidas, excelente               5   \n",
       "...                                  ...             ...   \n",
       "132368                    Ótimo produto!               5   \n",
       "132369                       Sensacional               5   \n",
       "132370                     Ótimo produto               4   \n",
       "132371              O produto não é bom.               1   \n",
       "132372              Produto não entregue               1   \n",
       "\n",
       "       recommend_to_a_friend  \\\n",
       "0                        Yes   \n",
       "1                        Yes   \n",
       "2                        Yes   \n",
       "3                        Yes   \n",
       "4                        Yes   \n",
       "...                      ...   \n",
       "132368                   Yes   \n",
       "132369                   Yes   \n",
       "132370                   Yes   \n",
       "132371                    No   \n",
       "132372                    No   \n",
       "\n",
       "                                              review_text  \\\n",
       "0       Estou contente com a compra entrega rápida o ú...   \n",
       "1       Por apenas R$1994.20,eu consegui comprar esse ...   \n",
       "2       SUPERA EM AGILIDADE E PRATICIDADE OUTRAS PANEL...   \n",
       "3       MEU FILHO AMOU! PARECE DE VERDADE COM TANTOS D...   \n",
       "4       A entrega foi no prazo, as americanas estão de...   \n",
       "...                                                   ...   \n",
       "132368  Vale muito, estou usando no controle do Xbox e...   \n",
       "132369  Prático e barato, super indico o produto para ...   \n",
       "132370  Chegou antes do prazo previsto e corresponde a...   \n",
       "132371  Material fraco, poderia ser melhor. Ficou deve...   \n",
       "132372  Comprei esse produto, quando chegou estava com...   \n",
       "\n",
       "        reviewer_birth_year reviewer_gender reviewer_state split_2 split_5  \n",
       "0                    1958.0               F             RJ   train   train  \n",
       "1                    1996.0               M             SC   train   train  \n",
       "2                    1984.0               M             SP   train   train  \n",
       "3                    1985.0               F             SP   valid   valid  \n",
       "4                    1994.0               M             MG   train   train  \n",
       "...                     ...             ...            ...     ...     ...  \n",
       "132368               1988.0               M             RS    test    test  \n",
       "132369               1979.0               F             SP    test    test  \n",
       "132370               1979.0               F             PR   train   train  \n",
       "132371               1991.0               M             RJ   train   train  \n",
       "132372               1982.0               F             ES   train   train  \n",
       "\n",
       "[132373 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>72.797409</td>\n",
       "      <td>72.818614</td>\n",
       "      <td>72.805560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>27.191260</td>\n",
       "      <td>27.166276</td>\n",
       "      <td>27.164224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label      train      valid       test\n",
       "0   Yes  72.797409  72.818614  72.805560\n",
       "1    No  27.191260  27.166276  27.164224"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>36.148936</td>\n",
       "      <td>36.450857</td>\n",
       "      <td>36.629400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>24.526431</td>\n",
       "      <td>24.038679</td>\n",
       "      <td>24.097296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20.674611</td>\n",
       "      <td>20.548463</td>\n",
       "      <td>20.811301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>12.282574</td>\n",
       "      <td>12.714361</td>\n",
       "      <td>12.275268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6.367448</td>\n",
       "      <td>6.247639</td>\n",
       "      <td>6.186735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label      train      valid       test\n",
       "0      5  36.148936  36.450857  36.629400\n",
       "1      4  24.526431  24.038679  24.097296\n",
       "2      1  20.674611  20.548463  20.811301\n",
       "3      3  12.282574  12.714361  12.275268\n",
       "4      2   6.367448   6.247639   6.186735"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking target distribution among splits\n",
    "check_distribution_label_2 = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(100.0*data[data.split_2=='train'].recommend_to_a_friend.value_counts()/data[data.split_2=='train'].shape[0]).rename(columns={'recommend_to_a_friend':'train'}),\n",
    "        pd.DataFrame(100.0*data[data.split_2=='valid'].recommend_to_a_friend.value_counts()/data[data.split_2=='valid'].shape[0]).rename(columns={'recommend_to_a_friend':'valid'}),\n",
    "        pd.DataFrame(100.0*data[data.split_2=='test'].recommend_to_a_friend.value_counts()/data[data.split_2=='test'].shape[0]).rename(columns={'recommend_to_a_friend':'test'})\n",
    "        ],\n",
    "    axis=1\n",
    ").reset_index().rename(columns={'index':'label'})\n",
    "\n",
    "check_distribution_label_5 = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(100.0*data[data.split_5=='train'].overall_rating.value_counts()/data[data.split_5=='train'].shape[0]).rename(columns={'overall_rating':'train'}),\n",
    "        pd.DataFrame(100.0*data[data.split_5=='valid'].overall_rating.value_counts()/data[data.split_5=='valid'].shape[0]).rename(columns={'overall_rating':'valid'}),\n",
    "        pd.DataFrame(100.0*data[data.split_5=='test'].overall_rating.value_counts()/data[data.split_5=='test'].shape[0]).rename(columns={'overall_rating':'test'})\n",
    "        ],\n",
    "    axis=1\n",
    ").reset_index().rename(columns={'index':'label'})\n",
    "\n",
    "display(check_distribution_label_2)\n",
    "display(check_distribution_label_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_tokenization(text, is_stemmed=False, remove_stopwords=False, remove_emojis=False):\n",
    "    text = re.sub(r\"(http|www)\\S+\", \"\", text) #remove URL\n",
    "    text = re.sub(r\"\\d{1,}.?\\d{0,}\", \" 0 \", text) #normalize numbers to zero\n",
    "    text = re.sub(r\"[\\⛤\\¿\\—\\…\\’\\•\\¡\\°\\º\\´\\!\\\"\\#\\%\\&\\\\\\'\\(\\)\\*\\+\\,\\-\\.\\/\\:\\;\\<\\=\\>\\?\\@\\[\\\\\\\\\\]\\^\\_\\`\\{\\|\\}\\~]{1,}\", \" \", text) # remove special characters\n",
    "    text = re.sub(r\"(?i)r? ?\\${1,}\", \" $ \", text) #normalize $\n",
    "    for emoji_i in UNICODE_EMOJI.keys():\n",
    "        if remove_emojis==False:\n",
    "            text = text.replace(emoji_i, ' ' + UNICODE_EMOJI[emoji_i].replace(':','') + ' ')\n",
    "        else:\n",
    "            text = text.replace(emoji_i, ' ')\n",
    "            \n",
    "    tokens_list = nltk.tokenize.word_tokenize(text, language='portuguese', preserve_line=False)\n",
    "    tokenized_text = []\n",
    "    for token in tokens_list:\n",
    "        if is_stemmed==True:\n",
    "            token = rslps_stemmer.stem(token).lower()\n",
    "        token = token.lower()\n",
    "        token = unidecode(token)\n",
    "        token = token.strip()\n",
    "        tokenized_text.append(token)\n",
    "    if remove_stopwords==True:\n",
    "        tokenized_text = [i for i in tokenized_text if i not in portuguese_stopwords]\n",
    "    tokenized_text = [i for i in tokenized_text if i not in ['','[?]']]\n",
    "    return tokenized_text\n",
    "\n",
    "def spacy_tokenization(text, is_lemmatized=False, remove_stopwords=False, remove_emojis=False):\n",
    "    text = re.sub(r\"(http|www)\\S+\", \"\", text) #remove URL\n",
    "    text = re.sub(r\"\\d{1,}.?\\d{0,}\", \" 0 \", text) #normalize numbers to zero\n",
    "    text = re.sub(r\"[\\⛤\\¿\\—\\…\\’\\•\\¡\\°\\º\\´\\!\\\"\\#\\%\\&\\\\\\'\\(\\)\\*\\+\\,\\-\\.\\/\\:\\;\\<\\=\\>\\?\\@\\[\\\\\\\\\\]\\^\\_\\`\\{\\|\\}\\~]{1,}\", \" \", text) # remove special characters\n",
    "    text = re.sub(r\"(?i)r? ?\\${1,}\", \" $ \", text) #normalize $\n",
    "    for emoji_i in UNICODE_EMOJI.keys():\n",
    "        if remove_emojis==False:\n",
    "            text = text.replace(emoji_i, ' ' + UNICODE_EMOJI[emoji_i].replace(':','') + ' ')\n",
    "        else:\n",
    "            text = text.replace(emoji_i, ' ')\n",
    "            \n",
    "    doc = nlp(text, disable=['tagger','parser','ner'])\n",
    "    tokenized_text = []\n",
    "    for token in doc:\n",
    "        if is_lemmatized==True:\n",
    "            token = token.lemma_\n",
    "        else:\n",
    "            token = token.text\n",
    "        token = token.lower()\n",
    "        token = unidecode(token)\n",
    "        token = token.strip()\n",
    "        tokenized_text.append(token)\n",
    "    if remove_stopwords==True:\n",
    "        tokenized_text = [i for i in tokenized_text if i not in portuguese_stopwords]\n",
    "    tokenized_text = [i for i in tokenized_text if i not in ['','[?]']]\n",
    "    return tokenized_text\n",
    "    \n",
    "# i = 1\n",
    "# print(data.review_text.values[i])\n",
    "# print('\\n')\n",
    "# print(nltk_tokenization(data.review_text.values[i], is_stemmed=False, remove_stopwords=True, remove_emojis=False))\n",
    "# print('\\n')\n",
    "# print(spacy_tokenization(data.review_text.values[i], is_lemmatized=False, remove_stopwords=True, remove_emojis=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132373/132373 [06:49<00:00, 323.23it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(data.shape[0])):\n",
    "    if (nltk_tokenization(data.review_text.values[i], is_stemmed=False, remove_stopwords=True) == spacy_tokenization(data.review_text.values[i], is_lemmatized=False, remove_stopwords=True))==False:\n",
    "        print(i)\n",
    "        print(nltk_tokenization(data.review_text.values[i], is_stemmed=False, remove_stopwords=True))\n",
    "        print('\\n')\n",
    "        print(spacy_tokenization(data.review_text.values[i], is_lemmatized=False, remove_stopwords=True))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(text, normalization_type=None, remove_stopwords=False, remove_emojis=False):\n",
    "    text = re.sub(r\"(http|www)\\S+\", \"\", text) #remove URL\n",
    "    text = re.sub(r\"\\d{1,}.?\\d{0,}\", \" 0 \", text) #normalize numbers to zero\n",
    "    text = re.sub(r\"[\\⛤\\¿\\—\\…\\’\\•\\¡\\°\\º\\´\\!\\\"\\#\\%\\&\\\\\\'\\(\\)\\*\\+\\,\\-\\.\\/\\:\\;\\<\\=\\>\\?\\@\\[\\\\\\\\\\]\\^\\_\\`\\{\\|\\}\\~]{1,}\", \" \", text) # remove special characters\n",
    "    text = re.sub(r\"(?i)r? ?\\${1,}\", \" $ \", text) #normalize $\n",
    "    for emoji_i in UNICODE_EMOJI.keys():\n",
    "        if remove_emojis==False:\n",
    "            text = text.replace(emoji_i, ' ' + UNICODE_EMOJI[emoji_i].replace(':','') + ' ')\n",
    "        else:\n",
    "            text = text.replace(emoji_i, ' ')\n",
    "            \n",
    "    doc = nlp(text, disable=['tagger','parser','ner'])\n",
    "    tokenized_text = []\n",
    "    for token in doc:\n",
    "        if normalization_type=='lemma':\n",
    "            token = token.lemma_\n",
    "        elif normalization_type=='stem':\n",
    "            token = rslps_stemmer.stem(token.text).lower()\n",
    "        else:\n",
    "            token = token.text\n",
    "        token = token.lower()\n",
    "        token = unidecode(token)\n",
    "        token = token.strip()\n",
    "        tokenized_text.append(token)\n",
    "    if remove_stopwords==True:\n",
    "        tokenized_text = [i for i in tokenized_text if i not in portuguese_stopwords]\n",
    "    tokenized_text = [i for i in tokenized_text if i not in ['','[?]']]\n",
    "    return tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train_2 = data.review_text[data.split_2=='train'].values\n",
    "X_valid_2 = data.review_text[data.split_2=='valid'].values\n",
    "X_test_2  = data.review_text[data.split_2=='test'].values\n",
    "y_train_2 = data.recommend_to_a_friend[data.split_2=='train'].values\n",
    "y_valid_2 = data.recommend_to_a_friend[data.split_2=='valid'].values\n",
    "y_test_2  = data.recommend_to_a_friend[data.split_2=='test'].values\n",
    "\n",
    "X_train_5 = data.review_text[data.split_5=='train'].values\n",
    "X_valid_5 = data.review_text[data.split_5=='valid'].values\n",
    "X_test_5  = data.review_text[data.split_5=='test'].values\n",
    "y_train_5 = data.overall_rating[data.split_5=='train'].values\n",
    "y_valid_5 = data.overall_rating[data.split_5=='valid'].values\n",
    "y_test_5  = data.overall_rating[data.split_5=='test'].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio-analysis",
   "language": "python",
   "name": "audio-analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
